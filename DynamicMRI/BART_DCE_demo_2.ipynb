{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART Tutorial: Reconstruction of Dynamic Contrast Enhanced (DCE) MRI\n",
    "## Practical Tools for Applying Compressed Sensing to 2D+Time Data\n",
    "\n",
    "### Part 2\n",
    "\n",
    "=========================================================================================================================\n",
    "\n",
    "Hello, welcome back!\n",
    "\n",
    "This is the **second** notebook of the Dynamic MRI tutorial. It is assumed that you are familiar with the materical in the first notebook, which is included in this repository and in named BART_DCE_demo.ipynb.\n",
    "\n",
    "This notebook includes additional demonstrations of ``bart pics`` with these regularizers:\n",
    "1. l1-wavelet in space\n",
    "2. Total Variation (TV) in time\n",
    "3. l1-wavelet in space + TVC in time\n",
    "\n",
    "Notice: this notebook should be run using a Python3 kernel.\n",
    "\n",
    "Efrat Shimron, UC Berkeley (efrat.s@berkeley.edu) and Jon Tamir, UT Austin (jtamir@utexas.edu).\n",
    "\n",
    "December 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART's interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we have two options for working with BART when using a Jupyter notebook with a python kernel:\n",
    "\n",
    "1. Using the **Command Line Interface (CLI)**\n",
    "2. Using **BART's python binder** - this enables reading the data from cfl into numpy arrays and working with numpy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to BART's python binding\n",
    "\n",
    "The `bart` module allows a user to execute any BART command-line tool via the following format:\n",
    "\n",
    "`<outputs> = bart(<nargs>, <command>, <arguments>, ...)`\n",
    "\n",
    "Where:\n",
    "\n",
    "`<outputs>`: the output of a BART command\n",
    "\n",
    "`<nargs>`: the number of outputs\n",
    "\n",
    "`<command>`: the command string and necessary flags\n",
    "\n",
    "`<arguments>`: the `<nargs>` data files passed in for use in the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction \n",
    "\n",
    "We will use the `pics` tool to perform ESPIRiT-based parallel imaging and compressed sensing. The basic usage is\n",
    "\n",
    "    bart pics [optimization options] [regularization options] kspace maps recon\n",
    "    \n",
    "See the full list with `bart pics -h`.\n",
    "There are several built-in regularization terms and transforms. We can see the options by invoking the help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bart pics -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "There are various options for regularization with bart pics. \n",
    "To see the different options for pics regularization, use `bart pics -Rh` flag:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bart pics -Rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next few sections we will show how to reconstruct the 2D+Time data using different regularizers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Example 1: *l*1-wavelet Regularizer in the Spatial Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### option 1: using the CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 maps.\n",
      "ESPIRiT reconstruction.\n",
      "Size: 220320 Samples: 17236 Acc: 12.78\n",
      "Linking args 1-2 of 4.\n",
      "Linking args 1-2 of 4.\n",
      "Linking args 1-2 of 4.\n",
      "Linking args 1-2 of 4.\n",
      "Calibration region...  (size: 1x5x2, pos: 0x31x89)\n",
      "Scaling: 329041.093750! (max = 329041.093750/p90 = 329041.093750/median = 153375.046875)\n",
      "Inverse scaling of the data: 329041.093750\n",
      "l1-wavelet regularization: 0.005000\n",
      "FISTA\n",
      "Linking args 1-2 of 4.\n",
      "Linking args 1-2 of 4.\n",
      "Linking args 1-2 of 4.\n",
      "Linking args 1-2 of 4.\n",
      "Linking args 2-3 of 5.\n",
      "Linking args 2-3 of 5.\n",
      "#It 000: 1.000000   \n",
      "#It 001: 0.266172   \n",
      "#It 002: 0.116492   \n",
      "#It 003: 0.066711   \n",
      "#It 004: 0.042221   \n",
      "#It 005: 0.027541   \n",
      "#It 006: 0.019003   \n",
      "#It 007: 0.014500   \n",
      "#It 008: 0.011795   \n",
      "#It 009: 0.009718   \n",
      "#It 010: 0.008024   \n",
      "#It 011: 0.006743   \n",
      "#It 012: 0.005852   \n",
      "#It 013: 0.005262   \n",
      "#It 014: 0.004839   \n",
      "#It 015: 0.004612   \n",
      "#It 016: 0.004402   \n",
      "#It 017: 0.004241   \n",
      "#It 018: 0.004193   \n",
      "#It 019: 0.004065   \n",
      "#It 020: 0.003956   \n",
      "#It 021: 0.003881   \n",
      "#It 022: 0.003848   \n",
      "#It 023: 0.003926   \n",
      "#It 024: 0.003859   \n",
      "#It 025: 0.003862   \n",
      "#It 026: 0.003818   \n",
      "#It 027: 0.003851   \n",
      "#It 028: 0.003838   \n",
      "#It 029: 0.003792   \n",
      "\n",
      "\t\tFISTA iterations: 30\n",
      "Total Time: 128.752181\n"
     ]
    }
   ],
   "source": [
    "! bart pics -d 5  -i 30 -p data/weights -R W:$(bart bitmask 0 1 2):0:0.005 data/ksp data/maps data/recon_l1wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "recon_l1wav_CLI = cfl.readcfl('data/recon_l1wav')\n",
    "recon_l1wav_CLI_sqz = recon_l1wav_CLI[0,:,:,0,0,0,0,0,0,0,:].squeeze()\n",
    "\n",
    "# display - let's view the first 8 time frames (of 20)\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "for t_ind in range(8):\n",
    "    im_frame = recon_l1wav_CLI_sqz[:,:,t_ind].squeeze()\n",
    "    plt.subplot(4,2,t_ind+1)\n",
    "    plt.imshow(np.abs(im_frame),cmap=\"gray\")\n",
    "    plt.clim(0,5)\n",
    "    plt.axis('off')\n",
    "    plt.title('time frame {}'.format(t_ind+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - view with Sigpy\n",
    "recon_l1wav_CLI_transposed = np.moveaxis(recon_l1wav_CLI_sqz,-1,0) # to display with SigPy, move the temporal dim to the 0-dim.\n",
    "recon_l1wav_CLI_rotated = np.rot90(recon_l1wav_CLI_transposed,2)\n",
    "\n",
    "%matplotlib notebook\n",
    "pl.ImagePlot(recon_l1wav_CLI_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### option 2: using the python binder + cfl files \n",
    "You can use this option if you sapved the sens maps to memoery in the cfl format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_l1wav = bart(1, 'pics -d 5 -i 30 -p {} -R W:7:0:0.005 {} {}'.format(\"data/weights\",\"data/ksp\",\"data/maps\"))  # explanation: 7 = $(bart bitmask 0 1 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### option3: using the python binder + numpy arrays\n",
    "Here we use the numpy arrays that we created earlier: ksp and sens_maps. We can also read them from memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that previously we ran these commands, which created the numpy arrays \"ksp\" and \"sens_maps\":\n",
    "# ksp = cfl.readcfl('data/ksp')\n",
    "# sens_maps = bart(1, 'ecalib -t 0.02 -c 0.5 -m 2', ksp_t_avg[:,:,:,:])\n",
    "\n",
    "recon_l1wav = bart(1, 'pics -d 5 -i 30 -p {} -R W:7:0:0.005'.format(\"data/weights\"), ksp , sens_maps)  # explanation: 7 = $(bart bitmask 0 1 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_l1wav_sqz = recon_l1wav[0,:,:,0,0,0,0,0,0,0,:].squeeze()\n",
    "\n",
    "# display - let's view the first 8 time frames (of 20)\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "for t_ind in range(8):\n",
    "    im_frame = recon_l1wav_sqz[:,:,t_ind].squeeze()\n",
    "    plt.subplot(4,2,t_ind+1)\n",
    "    plt.imshow(np.abs(im_frame),cmap=\"gray\")\n",
    "    plt.clim(0,5)\n",
    "    plt.axis('off')\n",
    "    plt.title('time frame {}'.format(t_ind+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - view with Sigpy\n",
    "\n",
    "recon_l1wav_transposed = np.moveaxis(recon_l1wav_sqz,-1,0) # to display with SigPy, move the temporal dim to the 0-dim.\n",
    "recon_l1wav_rotated = np.rot90(recon_l1wav_transposed,2)\n",
    "\n",
    "%matplotlib notebook\n",
    "pl.ImagePlot(recon_l1wav_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Example 2: Total Variation (TV) in Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bart pics -d 5 -i 100 -p data/weights -R T:$(bart bitmask 10):0:.04 data/ksp data/maps data/recon_tv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "recon_tv = cfl.readcfl('data/recon_tv')\n",
    "recon_tv_sqz = recon_tv[0,:,:,0,0,0,0,0,0,0,:].squeeze()\n",
    "\n",
    "# display - let's view the first 8 time frames (of 20)\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "for t_ind in range(8):\n",
    "    im_frame = recon_tv_sqz[:,:,t_ind].squeeze()\n",
    "    plt.subplot(4,2,t_ind+1)\n",
    "    plt.imshow(np.abs(im_frame),cmap=\"gray\")\n",
    "    plt.clim(0,5)\n",
    "    plt.axis('off')\n",
    "    plt.title('time frame {}'.format(t_ind+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Example 3: Two regularizers - *l*1-wavelet in Space and Total Variation (TV) in Time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### option 1: using BART's CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bart pics -d 5 -i 100 -p data/weights -R W:$(bart bitmask 0 1 2):0:0.001 -R T:$(bart bitmask 10):0:.04 data/ksp data/maps data/recon_wavtv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_wavTV = cfl.readcfl('data/recon_wavtv')\n",
    "\n",
    "# view the recon\n",
    "recon_wavTV_sqz = recon_wavTV[0,:,:,0,0,0,0,0,0,0,:].squeeze()\n",
    "recon_wavTV_transpose = np.moveaxis(recon_wavTV_sqz,-1,0) # to display with SigPy, move the temporal dim to the 0-dim.\n",
    "recon_wavTV_rotated = np.rot90(recon_wavTV_transpose,2)\n",
    "\n",
    "pl.ImagePlot(recon_wavTV_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### option 2: using bart's python binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_maps = cfl.readcfl('data/maps') \n",
    "print(sens_maps.dtype)\n",
    "print(sens_maps.shape)\n",
    "\n",
    "ksp = cfl.readcfl('data/ksp') \n",
    "print(ksp.dtype)\n",
    "print(ksp.shape)\n",
    "\n",
    "recon_wavTV = bart(1, 'pics -i 100 -p {} -R W:7:0:0.001 -R T:1024:0:.04 '.format(\"data/weights\"),ksp , sens_maps)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_wavTV_sqz = recon_wavTV[0,:,:,0,0,0,0,0,0,0,:].squeeze()\n",
    "\n",
    "# display - let's view the first 8 time frames (of 20)\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "for t_ind in range(8):\n",
    "    im_frame = recon_wavTV_sqz[:,:,t_ind].squeeze()\n",
    "    plt.subplot(4,2,t_ind+1)\n",
    "    plt.imshow(np.abs(im_frame),cmap=\"gray\")\n",
    "    plt.clim(0,5)\n",
    "    plt.axis('off')\n",
    "    plt.title('time frame {}'.format(t_ind+1))\n",
    "\n",
    "plt.suptitle('l1-Wavelet + TV regularization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the recon with Sigpy\n",
    "recon_wavTV_sqz = recon_wavTV[0,:,:,0,0,0,0,0,0,0,:].squeeze()\n",
    "recon_wavTV_transpose = np.moveaxis(recon_wavTV_sqz,-1,0) # to display with SigPy, move the temporal dim to the 0-dim.\n",
    "recon_wavTV_rotated = np.rot90(recon_wavTV_transpose,2)\n",
    "\n",
    "pl.ImagePlot(recon_wavTV_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the reconstructions of the different regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_l1wav = cfl.readcfl('data/recon_l1wav')\n",
    "recon_tv = cfl.readcfl('data/recon_tv')\n",
    "recon_wavTV = cfl.readcfl('data/recon_wavtv')\n",
    "recon_LLR = cfl.readcfl('data/recon_LLR')  # Notice: this reconstruction was created in the first jupyter notebook\n",
    "\n",
    "\n",
    "t_ind = 8  # choose a time frame\n",
    "\n",
    "recon_l1wav_t = recon_l1wav[0,:,:,0,0,0,0,0,0,0,t_ind].squeeze()\n",
    "recon_tv_t = recon_tv[0,:,:,0,0,0,0,0,0,0,t_ind].squeeze()\n",
    "recon_wavTV_t = recon_wavTV[0,:,:,0,0,0,0,0,0,0,t_ind].squeeze()\n",
    "recon_LLR_t = recon_LLR[0,:,:,0,0,0,0,0,0,0,t_ind].squeeze()\n",
    "\n",
    "recs_array = np.concatenate((recon_l1wav_t,recon_l1wav_t,recon_wavTV_t,recon_LLR_t),axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(np.abs(recon_l1wav_t),cmap=\"gray\")\n",
    "plt.clim(0,5)\n",
    "plt.axis('off')\n",
    "plt.title('l1-wav')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(np.abs(recon_tv_t),cmap=\"gray\")\n",
    "plt.clim(0,5)\n",
    "plt.axis('off')\n",
    "plt.title('TV')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(np.abs(recon_wavTV_t),cmap=\"gray\")\n",
    "plt.clim(0,5)\n",
    "plt.axis('off')\n",
    "plt.title('l1-wav + TV')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(np.abs(recon_LLR_t),cmap=\"gray\")\n",
    "plt.clim(0,5)\n",
    "plt.axis('off')\n",
    "plt.title('LLR')\n",
    "\n",
    "plt.suptitle('time frame {}'.format(t_ind+1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope you enjoyed this additional tutorial!\n",
    "\n",
    "Efrat & Jon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
